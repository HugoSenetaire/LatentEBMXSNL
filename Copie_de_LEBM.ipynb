{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HugoSenetaire/LatentEBMXSNL/blob/main/Copie_de_LEBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro"
      ],
      "metadata": {
        "id": "34fS3XGHo0D9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lsia_c1YpQq"
      },
      "outputs": [],
      "source": [
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torchvision as tv\n",
        "import torchvision.transforms as tfm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "VA303z-leicx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "ZAlWRIKFd5P_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as t, torch.nn as nn\n",
        "import torchvision as tv, torchvision.transforms as tfm\n",
        "\n",
        "dataset = \"SVHN\"\n",
        "\n",
        "save_image_every = 50\n",
        "log_every = 10\n",
        "\n",
        "if dataset == \"SVHN_original\":\n",
        "  img_size, batch_size = 32, 256\n",
        "  nz, nc, ndf, ngf = 100, 3, 200, 64\n",
        "  K_0, a_0, K_1, a_1 = 60, 0.4, 40, 0.1\n",
        "  llhd_sigma = 0.3\n",
        "  n_iter = 70000\n",
        "  device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
        "elif dataset == \"SVHN\":\n",
        "  img_size, batch_size = 32, 256\n",
        "  nz, nc, ndf, ngf = 100, 3, 200, 64\n",
        "  K_0, a_0, K_1, a_1 = 20, 0.4, 20, 0.1\n",
        "  llhd_sigma = 0.3\n",
        "  n_iter = 70000\n",
        "  device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
        "\n",
        "elif dataset == \"MNIST\":\n",
        "  img_size, batch_size = 28, 256\n",
        "  nz, nc, ndf, ngf = 16, 1, 200, 16\n",
        "  K_0, a_0, K_1, a_1 = 20, 0.4, 20, 0.1\n",
        "  llhd_sigma = 0.3\n",
        "  n_iter = 70000\n",
        "  device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
        "elif dataset == \"CIFAR_10\" :\n",
        "  img_size, batch_size = 28, 256\n",
        "  nz, nc, ndf, ngf = 16, 1, 200, 16\n",
        "  K_0, a_0, K_1, a_1 = 20, 0.4, 20, 0.1\n",
        "  llhd_sigma = 0.3\n",
        "  n_iter = 70000\n",
        "  device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "\n",
        "cfg = {\n",
        "    \"dataset\": dataset,\n",
        "    \"img_size\": img_size,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"nz\": nz,\n",
        "    \"nc\": nc,\n",
        "    \"ndf\": ndf,\n",
        "    \"ngf\": ngf,\n",
        "    \"K_0\": K_0,\n",
        "    \"a_0\": a_0,\n",
        "    \"K_1\": K_1,\n",
        "    \"a_1\": a_1,\n",
        "    \"llhd_sigma\": llhd_sigma,\n",
        "    \"n_iter\": n_iter,\n",
        "    \"device\": device,\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "gAD6DtTMZPBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if dataset.startswith('SVHN'):\n",
        "  transform = tfm.Compose([tfm.Resize(img_size), tfm.ToTensor(), tfm.Normalize(([0.5]*3), ([0.5]*3)),])\n",
        "  data = t.stack([x[0] for x in tv.datasets.SVHN(download=True, root='data/svhn', transform=transform)]).to(device)\n",
        "elif dataset == \"MNIST\":\n",
        "  transform = tfm.Compose([tfm.Resize(img_size), tfm.ToTensor(), tfm.Normalize((0.5), (0.5),)])\n",
        "  data = t.stack([x[0] for x in tv.datasets.MNIST(download=True, root='data/mnist', transform=transform)]).to(device)\n"
      ],
      "metadata": {
        "id": "wGo-mr5lTH4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network"
      ],
      "metadata": {
        "id": "-GTPR5uud6Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class _G_MNIST(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.gen = nn.Sequential(nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0), nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(ngf*8, ngf*4, 3, 2, 1), nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1), nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(ngf*2, nc, 4, 2, 1), nn.Tanh())\n",
        "    def forward(self, z):\n",
        "        return self.gen(z)\n",
        "\n",
        "class _G_SVHN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.gen = nn.Sequential(nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0), nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1), nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1), nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(ngf*2, nc, 4, 2, 1), nn.Tanh())\n",
        "    def forward(self, z):\n",
        "        return self.gen(z)\n",
        "\n",
        "\n",
        "class _Encoder_SVHN(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_net = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=nc, out_channels=ngf*2, kernel_size=5, stride=2, padding=2),\n",
        "                nn.LeakyReLU(0.3),\n",
        "                nn.Conv2d(in_channels=ngf*2, out_channels=ngf*4, kernel_size=5, stride=2, padding=2),\n",
        "                nn.LeakyReLU(0.3),\n",
        "                nn.Conv2d(in_channels=ngf*4, out_channels=ngf*8, kernel_size=5, stride=2, padding=2),\n",
        "                nn.LeakyReLU(0.3),\n",
        "        )\n",
        "        self.fc=nn.Sequential(\n",
        "                # nn.Linear(16*ngf*8, 256),\n",
        "                # nn.ReLU(),\n",
        "                # nn.Linear(256, 2*nz),\n",
        "                nn.Linear(16*ngf*8, 2*nz),\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_net(x)\n",
        "        x = x.flatten(1)\n",
        "        return self.fc(x)\n",
        "\n",
        "class _E_MNIST(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.ebm = nn.Sequential(nn.Linear(nz, ndf), nn.LeakyReLU(0.2),\n",
        "            nn.Linear(ndf, ndf), nn.LeakyReLU(0.2),\n",
        "            nn.Linear(ndf, ndf), nn.LeakyReLU(0.2),\n",
        "            nn.Linear(ndf, 1))\n",
        "    def forward(self, z):\n",
        "        return self.ebm(z.squeeze()).view(-1, 1, 1, 1)\n",
        "\n",
        "class _E_SVHN(nn.Module):\n",
        "  def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mean = torch.nn.parameter.Parameter(torch.tensor(0.,),requires_grad=False)\n",
        "        self.std = torch.nn.parameter.Parameter(torch.tensor(1.,),requires_grad=False)\n",
        "        self.ebm = nn.Sequential(nn.Linear(nz, ndf), nn.LeakyReLU(0.2),\n",
        "            nn.Linear(ndf, ndf), nn.LeakyReLU(0.2),\n",
        "            nn.Linear(ndf, ndf), nn.LeakyReLU(0.2),\n",
        "            nn.Linear(ndf, 1))\n",
        "  def forward(self, z):\n",
        "      z_squeeze = z.squeeze()\n",
        "      energy = self.ebm(z_squeeze)\n",
        "      base_dist = torch.distributions.normal.Normal(self.mean, self.std).log_prob(z_squeeze).detach()\n",
        "      base_dist = base_dist.reshape(z.shape).flatten(1).sum(1,).reshape(-1,1)\n",
        "      # print(energy.shape)\n",
        "      # print(base_dist.shape)\n",
        "      return (energy-base_dist).view(-1, 1, 1, 1)\n",
        "\n",
        "\n",
        "class _Encoder_MNIST(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_net = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=nc, out_channels=ngf*2, kernel_size=5, stride=2, padding=2),\n",
        "                nn.LeakyReLU(0.3),\n",
        "                nn.Conv2d(in_channels=ngf*2, out_channels=ngf*4, kernel_size=5, stride=2, padding=2),\n",
        "                nn.LeakyReLU(0.3),\n",
        "                nn.Conv2d(in_channels=ngf*4, out_channels=ngf*8, kernel_size=5, stride=2, padding=2),\n",
        "                nn.LeakyReLU(0.3),\n",
        "        )\n",
        "        self.fc=nn.Sequential(\n",
        "                # nn.Linear(16*ngf*8, 256),\n",
        "                # nn.ReLU(),\n",
        "                # nn.Linear(256, 2*nz),\n",
        "                nn.Linear(16*ngf*8, 2*nz),\n",
        "                )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_net(x)\n",
        "        x = x.flatten(1)\n",
        "        return self.fc(x)\n",
        "\n",
        "if dataset == \"MNIST\":\n",
        "  _G = _G_MNIST\n",
        "  _Encoder = _Encoder_MNIST\n",
        "  _E = _E_MNIST\n",
        "elif dataset.startswith(\"SVHN\"):\n",
        "  _G = _G_SVHN\n",
        "  _Encoder = _Encoder_SVHN\n",
        "  _E = _E_SVHN\n",
        "\n",
        "else :\n",
        "  raise NotImplementedError()\n"
      ],
      "metadata": {
        "id": "prvOyRkXaQpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "WTgZgu-Xd9R-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample"
      ],
      "metadata": {
        "id": "aiN-85Qho5Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def sample_p_data():\n",
        "    return data[t.LongTensor(batch_size).random_(0, data.size(0))].detach()\n",
        "\n",
        "def sample_p_0(n=batch_size):\n",
        "    return t.randn(*[n, nz, 1, 1]).to(device)\n",
        "\n",
        "def sample_langevin_prior(z, E):\n",
        "    z = z.clone().detach().requires_grad_(True)\n",
        "    for i in range(K_0):\n",
        "        en = E(z)\n",
        "        z_grad = t.autograd.grad(en.sum(), z)[0]\n",
        "        z.data = z.data - 0.5 * a_0 * a_0 * (z_grad + 1.0 / z.data) + a_0 * t.randn_like(z).data\n",
        "    return z.detach()\n",
        "\n",
        "def sample_langevin_posterior(z, x, G, E):\n",
        "    z = z.clone().detach().requires_grad_(True)\n",
        "    for i in range(K_1):\n",
        "        x_hat = G(z)\n",
        "        g_log_lkhd = 1.0 / (2.0 * llhd_sigma * llhd_sigma) * mse(x_hat, x)\n",
        "        grad_g = t.autograd.grad(g_log_lkhd, z)[0]\n",
        "        en = E(z)\n",
        "        grad_e = t.autograd.grad(en.sum(), z)[0]\n",
        "        z.data = z.data - 0.5 * a_1 * a_1 * (grad_g + grad_e + 1.0 / z.data) + a_1 * t.randn_like(z).data\n",
        "    return z.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HpEm09zVaVk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QlZx5Qk1PaFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clipping Gradients"
      ],
      "metadata": {
        "id": "QiJnNDTYo7OD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "def clip_grad_adam(parameters, optimizer, nb_sigmas = 3):\n",
        "    with torch.no_grad():\n",
        "        for group in optimizer.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None or p.grad.data is None:\n",
        "                    continue\n",
        "                state = optimizer.state[p]\n",
        "\n",
        "                if 'step' not in state or state['step'] < 1:\n",
        "                    continue\n",
        "\n",
        "                step = state['step']\n",
        "                exp_avg_sq = state['exp_avg_sq']\n",
        "                _, beta2 = group['betas']\n",
        "\n",
        "                bound = nb_sigmas * torch.sqrt(exp_avg_sq / (1 - beta2 ** step)) + 0.1\n",
        "                p.grad.data.copy_(torch.max(torch.min(p.grad.data, bound), -bound))\n",
        "\n",
        "\n",
        "def grad_clipping(net, net_name, cfg, current_optim, logger, step):\n",
        "        # Grad clipping\n",
        "        clip_grad_type = cfg[net_name+\"_clip_grad_type\"]\n",
        "        clip_grad_value = cfg[net_name+\"_clip_grad_value\"]\n",
        "        nb_sigmas = cfg[net_name+\"_nb_sigma\"]\n",
        "        if clip_grad_type == \"norm\":\n",
        "            if clip_grad_value is not None:\n",
        "                logger.log({\"train/{}_clip_grad_norm\".format(net_name): clip_grad_value}, step=step)\n",
        "                torch.nn.utils.clip_grad_norm_(\n",
        "                    parameters=net.parameters(),\n",
        "                    max_norm=clip_grad_value,\n",
        "                )\n",
        "        elif clip_grad_type == \"abs\":\n",
        "            if clip_grad_value is not None:\n",
        "                logger.log({\"train/{}_clip_grad_abs\".format(net_name): clip_grad_value}, step=step)\n",
        "                torch.nn.utils.clip_grad_value_(\n",
        "                    parameters=net.parameters(),\n",
        "                    clip_value=clip_grad_value,\n",
        "                )\n",
        "        elif clip_grad_type == \"adam\":\n",
        "            if nb_sigmas is not None:\n",
        "                logger.log({\"train/{}_clip_grad_adam_nb_sigmas\".format(net_name): nb_sigmas}, step=step)\n",
        "                clip_grad_adam(net.parameters(),\n",
        "                        current_optim,\n",
        "                        nb_sigmas=nb_sigmas)\n",
        "        elif clip_grad_type is None:\n",
        "            pass\n",
        "        else :\n",
        "            raise NotImplementedError\n",
        "\n",
        "def grad_clipping_all_net(liste_network = [], liste_name = [], liste_optim = [], logger = None, cfg =None, step=None):\n",
        "    for net, net_name, optim in zip(liste_network, liste_name, liste_optim):\n",
        "      grad_clipping(net, net_name, cfg, optim, logger, step=step)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HDSOVcSJiPm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularization"
      ],
      "metadata": {
        "id": "cT2uve5no9H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import grad as torch_grad\n",
        "\n",
        "def wgan_gradient_penalty(ebm, x, x_gen,):\n",
        "    batch_size = x.size()[0]\n",
        "    min_data_len = min(batch_size,x_gen.size()[0])\n",
        "    # Calculate interpolation\n",
        "    epsilon = torch.rand(min_data_len, device=x.device)\n",
        "    for _ in range(len(x.shape) - 1):\n",
        "        epsilon = epsilon.unsqueeze(-1)\n",
        "    epsilon = epsilon.expand(min_data_len, *x.shape[1:])\n",
        "    epsilon = epsilon.to(x.device)\n",
        "    interpolated = epsilon*x.data[:min_data_len] + (1-epsilon)*x_gen.data[:min_data_len]\n",
        "    interpolated = interpolated.detach()\n",
        "    interpolated.requires_grad_(True)\n",
        "\n",
        "    # Calculate probability of interpolated examples\n",
        "    prob_interpolated = ebm.f_theta(interpolated).flatten(1).sum(1)\n",
        "\n",
        "    # Calculate gradients of probabilities with respect to examples\n",
        "    gradients = torch_grad(outputs=prob_interpolated, inputs=interpolated,\n",
        "                           grad_outputs=torch.ones(prob_interpolated.size()).to(x.device),\n",
        "                           create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
        "    # so flatten to easily take norm per example in batch\n",
        "    gradients = gradients.view(min_data_len, -1)\n",
        "\n",
        "    # Derivatives of the gradient close to 0 can cause problems because of\n",
        "    # the square root, so manually calculate norm and add epsilon\n",
        "    gradients_norm = torch.sum(gradients ** 2, dim=1).mean()\n",
        "    return gradients_norm\n",
        "\n",
        "def regularization(ebm, x, x_gen, energy_data, energy_samples, cfg, logger, step):\n",
        "        '''\n",
        "        Compute different gradients and regularization terms given the energy or the loss.\n",
        "        '''\n",
        "        dic_loss = {}\n",
        "        # Regularization\n",
        "        if cfg[\"l2_grad\"] is not None and cfg[\"l2_grad\"] > 0:\n",
        "            grad_norm = wgan_gradient_penalty(ebm, x, x_gen)\n",
        "            dic_loss[\"l2_grad\"] = cfg[\"l2_grad\"] * grad_norm\n",
        "            logger.log({\"penalty/grad_norm\": grad_norm},step=step)\n",
        "            logger.log({\"penalty/regularization_l2_grad\": dic_loss[\"l2_grad\"]},step=step)\n",
        "\n",
        "        if cfg[\"l2_output\"] is not None and cfg[\"l2_output\"] > 0:\n",
        "            l2_output = ((energy_data**2).mean() + (energy_samples**2).mean())\n",
        "            dic_loss[\"loss_l2_output\"] = cfg[\"l2_output\"] * l2_output\n",
        "            logger.log({\"penalty/l2_output\": l2_output},step=step)\n",
        "            logger.log({\"penalty/regularization_l2_output\": dic_loss[\"loss_l2_output\"]},step=step)\n",
        "\n",
        "        if cfg[\"l2_param\"] is not None and cfg[\"l2_param\"] > 0:\n",
        "            penalty = 0.\n",
        "            len_params = 0.\n",
        "            for params in ebm.parameters():\n",
        "                len_params += params.numel()\n",
        "                penalty += torch.sum(params**2)\n",
        "            penalty = penalty / len_params\n",
        "            dic_loss[\"loss_l2_param\"] = cfg[\"l2_param\"] * penalty\n",
        "            logger.log({\"penalty/l2_param\": penalty},step=step)\n",
        "            logger.log({\"penalty/regularization_l2_param\": dic_loss[\"loss_l2_param\"]},step=step)\n",
        "\n",
        "        return dic_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "5IeEAjh7lNoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logger"
      ],
      "metadata": {
        "id": "N90mKwYyqqoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from IPython import display\n",
        "import torch\n",
        "\n",
        "global_dic_error = {}\n",
        "\n",
        "def log(step, dic_loss, logger):\n",
        "  for key,value in dic_loss.items():\n",
        "    logger.log({key:value},step=step)\n",
        "\n",
        "\n",
        "def draw_samples(fig, axs, prior_0, langevin_prior, posterior, approximate_posterior, step, dic_loss, logger):\n",
        "  grid_prior = tv.utils.make_grid(prior_0/2+0.5,)\n",
        "  grid_langevin_prior = tv.utils.make_grid(langevin_prior/2+0.5)\n",
        "  grid_langevin_posterior = tv.utils.make_grid(posterior/2+0.5)\n",
        "\n",
        "  axs[0].imshow(grid_prior.detach().cpu().permute(1,2,0).numpy())\n",
        "  axs[0].set_title(\"BaseDistribution\")\n",
        "  axs[1].imshow(grid_langevin_prior.detach().cpu().permute(1,2,0).numpy())\n",
        "  axs[1].set_title(\"Prior\")\n",
        "  axs[2].imshow(grid_langevin_posterior.detach().cpu().permute(1,2,0).numpy())\n",
        "  axs[2].set_title(\"Posterior\")\n",
        "\n",
        "  if approximate_posterior is not None :\n",
        "    grid_langevin_approximate_posterior = tv.utils.make_grid(approximate_posterior/2+0.5)\n",
        "    axs[3].set_title(\"Approximate Posterior\")\n",
        "    axs[3].imshow(grid_langevin_approximate_posterior.detach().cpu().permute(1,2,0).numpy())\n",
        "\n",
        "  img= wandb.Image(fig, caption=f\"Step {step}\")\n",
        "  logger.log({f\"All_samples.png\": img},step=step)\n",
        "\n",
        "\n",
        "\n",
        "  title = \"Step:{}, time per step : {:2.3f}\".format(step, (time.time()-start_time)/10,)\n",
        "  for key,value in dic_loss.items():\n",
        "    title+=\", {} : {:2.3f}\".format(key,value)\n",
        "    logger.log({key:value},step=step)\n",
        "  fig.suptitle(title)\n",
        "  display.display(fig)\n",
        "  display.clear_output(wait=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dpFztgHcaXPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "D9-WkJlqajai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different Trainer"
      ],
      "metadata": {
        "id": "VDbf6APedz20"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0vABan6Wqvkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_cd(x, G,E, loss, optE, optG, logger, cfg):\n",
        "  for i in range(n_iter):\n",
        "      x = sample_p_data()\n",
        "      z_e_0, z_g_0 = sample_p_0(), sample_p_0()\n",
        "      z_e_k, z_g_k = sample_langevin_prior(z_e_0, E), sample_langevin_posterior(z_g_0, x, G, E)\n",
        "\n",
        "\n",
        "      optG.zero_grad()\n",
        "      x_hat = G(z_g_k.detach())\n",
        "      loss_g = mse(x_hat, x) / batch_size\n",
        "      loss_g.backward()\n",
        "      grad_clipping_all_net([G], [\"G\"], [optG], logger, cfg, i)\n",
        "      optG.step()\n",
        "\n",
        "      optE.zero_grad()\n",
        "      en_pos, en_neg = E(z_g_k.detach()).mean(), E(z_e_k.detach()).mean()\n",
        "      loss_e = en_pos - en_neg\n",
        "      regularization(E, z_g_k, z_e_k, en_pos, en_neg, cfg, logger,i)\n",
        "      loss_e.backward()\n",
        "      grad_clipping_all_net([E], [\"E\"], [optE], logger, cfg, i)\n",
        "      optE.step()\n",
        "      dic_loss = {\n",
        "          \"loss_e\": loss_e,\n",
        "          \"loss_g\": loss_g,\n",
        "          \"en_pos\": en_pos,\n",
        "          \"en_neg\": en_neg,\n",
        "        }\n",
        "\n",
        "      if i%log_every == 0 :\n",
        "        log(i, dic_loss, logger)\n",
        "      if i%save_image_every== 0:\n",
        "        x_prior_langevin = G(z_e_k)\n",
        "        x_prior = G(z_e_0)\n",
        "        x_hat = x_hat\n",
        "        draw_samples(fig, axs, x_prior[:64], x_prior_langevin[:64], x_hat[:64], None, i, dic_loss, logger)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q1ETYPFyzN-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_cd_trick(n_iter, G,E, loss, optE, optG, logger):\n",
        "  proposal = torch.distributions.normal.Normal(torch.tensor(cfg[\"proposal_mean\"],device=device),torch.tensor(cfg[\"proposal_std\"],device=device))\n",
        "  base_dist = torch.distributions.normal.Normal(torch.tensor(0,device=device),torch.tensor(1,device=device))\n",
        "\n",
        "  for i in range(n_iter):\n",
        "      x = sample_p_data()\n",
        "      z_e_0, z_g_0 = sample_p_0(), sample_p_0()\n",
        "      z_e_k, z_g_k = sample_langevin_prior(z_e_0, E), sample_langevin_posterior(z_g_0, x, G, E)\n",
        "\n",
        "\n",
        "      optG.zero_grad()\n",
        "      x_hat = G(z_g_k.detach())\n",
        "      loss_g = mse(x_hat, x) / batch_size\n",
        "      loss_g.backward()\n",
        "      grad_clipping_all_net([G], [\"G\"], [optG], logger, cfg, i)\n",
        "      optG.step()\n",
        "\n",
        "      optE.zero_grad()\n",
        "      # en_pos, en_neg = E(z_g_k.detach()).mean(), E(z_e_k.detach()).mean()\n",
        "      energy_posterior = E(z_g_k.detach()).flatten(1).sum(1)\n",
        "      z_proposal = proposal.sample(z_g_k.shape)\n",
        "      energy_proposal = E(z_proposal.detach()).flatten(1).sum(1)\n",
        "      base_dist_z_proposal = base_dist.log_prob(z_proposal.flatten(1)).sum(1)\n",
        "      base_dist_z_posterior = base_dist.log_prob(z_g_k.flatten(1)).sum(1)\n",
        "      base_dist_z_base_dist = base_dist.log_prob(z_e_0.flatten(1)).sum(1)\n",
        "      proposal_z_proposal = proposal.log_prob(z_proposal.flatten(1)).sum(1)\n",
        "      proposal_z_posterior = proposal.log_prob(z_g_k.flatten(1)).sum(1)\n",
        "      proposal_z_base_dist = proposal.log_prob(z_e_0.flatten(1)).sum(1)\n",
        "\n",
        "\n",
        "      log_partition_estimate = torch.logsumexp(-energy_proposal,0) - math.log(energy_proposal.shape[0])\n",
        "      loss_e = (energy_posterior-proposal_z_posterior).mean() + log_partition_estimate.exp() -1\n",
        "      regularization(E, z_g_k, z_proposal, energy_posterior, energy_proposal, cfg, logger,i)\n",
        "      loss_e.backward()\n",
        "      grad_clipping_all_net([E], [\"E\"], [optE], logger, cfg, i)\n",
        "      optE.step()\n",
        "      dic_loss = {\n",
        "          \"loss_e\": loss_e.mean().item(),\n",
        "          \"loss_g\": loss_g.mean().item(),\n",
        "          \"base_dist_z_proposal\": base_dist_z_proposal.mean().item(),\n",
        "          \"base_dist_z_posterior\":base_dist_z_posterior.mean().item(),\n",
        "          \"base_dist_z_base_dist\": base_dist_z_base_dist.mean().item(),\n",
        "          \"proposal_z_proposal\": proposal_z_proposal.mean().item(),\n",
        "          \"proposal_z_posterior\":proposal_z_posterior.mean().item(),\n",
        "          \"proposal_z_base_dist\": proposal_z_base_dist.mean().item(),\n",
        "          \"en_pos\": energy_posterior.mean().item(),\n",
        "          \"en_neg\": energy_proposal.mean().item(),\n",
        "          \"log_z\" : log_partition_estimate.item()\n",
        "      }\n",
        "\n",
        "      if i%log_every == 0 :\n",
        "        log(i, dic_loss, logger)\n",
        "      if i%save_image_every== 0:\n",
        "        x_prior_langevin = G(z_e_k)\n",
        "        x_prior = G(z_e_0)\n",
        "        x_hat = x_hat\n",
        "\n",
        "        draw_samples(fig, axs, x_prior[:64], x_prior_langevin[:64], x_hat[:64], None, i, dic_loss, logger)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DDwUHy3Ua75S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_auto_encoder(n_tier, G, E, Encoder, loss, optE, optG, optEncoder, logger):\n",
        "  log_var_p = None\n",
        "  for i in range(n_iter):\n",
        "    optG.zero_grad()\n",
        "    optE.zero_grad()\n",
        "    optEncoder.zero_grad()\n",
        "\n",
        "    x = sample_p_data()\n",
        "    z_e_0, z_g_0 = sample_p_0(), sample_p_0()\n",
        "    mu_q, log_var_q = Encoder(x).chunk(2,1)\n",
        "\n",
        "    x_hat = G(mu_q.reshape(-1,nz,1,1))\n",
        "\n",
        "    loss_g = (mse(x_hat, x) / batch_size)\n",
        "\n",
        "    loss_g.backward()\n",
        "    optG.step()\n",
        "    optE.step()\n",
        "    dic_loss = {\"mse\":loss_g,\n",
        "                \"mu_q_std\": mu_q.flatten(1).std(1).mean()}\n",
        "\n",
        "\n",
        "    if i%log_every == 0 :\n",
        "        log(i, dic_loss, logger)\n",
        "    if i%save_image_every== 0:\n",
        "        draw_samples(fig, axs, x_hat[:64], x_hat[:64], x_hat[:64], x_hat[:64], i, dic_loss, logger)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aX6wh_uiMt1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def train_elbo_notrick(n_iter, G, E, Encoder, loss, optE, optG, optEncoder, logger):\n",
        "  log_var_p = None\n",
        "  for i in range(n_iter):\n",
        "      optG.zero_grad()\n",
        "      optE.zero_grad()\n",
        "      optEncoder.zero_grad()\n",
        "\n",
        "\n",
        "      x = sample_p_data()\n",
        "      z_e_0, z_g_0 = sample_p_0(), sample_p_0()\n",
        "\n",
        "      mu_q, log_var_q = Encoder(x).chunk(2,1)\n",
        "      if log_var_p is None :\n",
        "        log_var_p = torch.log(torch.full_like(log_var_q, llhd_sigma)).pow(2)\n",
        "\n",
        "      std_q = torch.exp(0.5*log_var_q)\n",
        "      eps = torch.randn_like(mu_q)\n",
        "      z_q = (eps.mul(std_q).add_(mu_q)).reshape(-1,nz,1,1)\n",
        "\n",
        "      x_hat = G(z_q)\n",
        "      loss_g = (mse(x_hat, x) / batch_size)/(llhd_sigma**2)\n",
        "      KL_loss = 0.5 * (log_var_p - log_var_q -1 +  (log_var_q.exp() + mu_q.pow(2))/log_var_p.exp())\n",
        "      KL_loss = KL_loss.sum(dim=1).mean(dim=0)\n",
        "\n",
        "      loss_total = loss_g + KL_loss\n",
        "      loss_total.backward()\n",
        "\n",
        "      dic_loss = {\n",
        "          \"loss_g\":loss_g.item(),\n",
        "          \"KL_loss\":KL_loss.item(),\n",
        "          \"elbo\": -loss_total.item(),\n",
        "      }\n",
        "      optE.step()\n",
        "      optG.step()\n",
        "      optEncoder.step()\n",
        "\n",
        "      if i%log_every == 0 :\n",
        "        log(i, dic_loss, logger)\n",
        "      if i%save_image_every== 0:\n",
        "        z_e_k, z_g_k = sample_langevin_prior(z_e_0, E), sample_langevin_posterior(z_g_0, x, G, E)\n",
        "        x_prior_langevin = G(z_e_k)\n",
        "        x_prior = G(z_e_0)\n",
        "        x_posterior = G(z_g_k)\n",
        "        x_approximate_posterior = G(z_q)\n",
        "        draw_samples(fig, axs, x_prior[:64], x_prior_langevin[:64], x_posterior[:64], x_approximate_posterior[:64], i, dic_loss, logger)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y6zPsYhEqy6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def train_elbo_withtrick(n_iter, G, E, Encoder, loss, optE, optG, optEncoder, cfg, logger= None):\n",
        "  \"\"\"\n",
        "  Here in the case where the base distribution is actually the proposal, then\n",
        "  i can just calculate the entropy of the posterior, then I get loss ebm on the same level, hopefully\n",
        "  \"\"\"\n",
        "\n",
        "  fix_encoder = cfg[\"fix_encoder\"]\n",
        "  fix_decoder= cfg[\"fix_decoder\"]\n",
        "  log_var_p = None\n",
        "  device = next(G.parameters()).device\n",
        "  proposal = torch.distributions.normal.Normal(torch.tensor(cfg[\"proposal_mean\"],device=device),torch.tensor(cfg[\"proposal_std\"],device=device))\n",
        "  base_dist = torch.distributions.normal.Normal(torch.tensor(0,device=device, dtype=torch.float32),torch.tensor(1,device=device, dtype=torch.float32))\n",
        "\n",
        "  for i in range(n_iter):\n",
        "      optG.zero_grad()\n",
        "      optE.zero_grad()\n",
        "      optEncoder.zero_grad()\n",
        "      x = sample_p_data()\n",
        "\n",
        "      z_e_0, z_g_0 = sample_p_0(), sample_p_0()\n",
        "      mu_q, log_var_q = Encoder(x).chunk(2,1)\n",
        "      log_var_p = torch.log(torch.full_like(log_var_q, llhd_sigma)).pow(2)\n",
        "      std_q = torch.exp(0.5*log_var_q)\n",
        "\n",
        "      # Reparam trick\n",
        "      eps = torch.randn_like(mu_q)\n",
        "      z_q = (eps.mul(std_q).add_(mu_q)).reshape(-1,nz,1,1)\n",
        "      x_hat = G(z_q)\n",
        "\n",
        "\n",
        "      # Gaussian loss :\n",
        "      loss_g = (mse(x_hat, x) / batch_size)/(llhd_sigma**2)\n",
        "\n",
        "      # KL without ebm\n",
        "      KL_loss = 0.5 * (log_var_p - log_var_q -1 +  (log_var_q.exp() + mu_q.pow(2))/log_var_p.exp())\n",
        "      KL_loss = KL_loss.sum(dim=1).mean(dim=0)\n",
        "\n",
        "      # Entropy posterior\n",
        "      entropy_posterior = torch.sum(0.5* (math.log(2*math.pi) +  log_var_q + 1), dim=1).mean()\n",
        "\n",
        "      # Energy :\n",
        "      energy_approximate = E(z_q).flatten(1).sum(1)\n",
        "      energy_base_dist = E(z_e_0).flatten(1).sum(1)\n",
        "\n",
        "      base_dist_z_approximate = base_dist.log_prob(z_q.flatten(1)).sum(1)\n",
        "      base_dist_z_base_dist = base_dist.log_prob(z_e_0.flatten(1)).sum(1)\n",
        "\n",
        "\n",
        "      log_partition_estimate = torch.logsumexp(-energy_base_dist -base_dist_z_base_dist,0) - math.log(energy_base_dist.shape[0])\n",
        "      loss_ebm = (energy_approximate - base_dist_z_approximate).mean() + log_partition_estimate.exp() -1\n",
        "      # loss_ebm = (energy_approximate - base_dist_approximate).mean() + log_partition_estimate\n",
        "\n",
        "\n",
        "\n",
        "      loss_total = loss_g - entropy_posterior + loss_ebm\n",
        "      regularization(E, z_q, z_e_0, energy_approximate, energy_base_dist, cfg, logger,i)\n",
        "      loss_total.backward()\n",
        "      grad_clipping_all_net([E,G,Encoder], [\"E\", \"G\", \"Encoder\"], [optE, optG, optEncoder,], logger, cfg, i)\n",
        "\n",
        "      dic_loss = {\n",
        "          \"loss_g\":loss_g.item(),\n",
        "          \"entropy_posterior\":entropy_posterior.item(),\n",
        "          \"loss_ebm\": loss_ebm.item(),\n",
        "          \"base_dist_z_approximate\": base_dist_z_approximate.mean().item(),\n",
        "          \"base_dist_z_base_dist\" : base_dist_z_base_dist.mean().item(),\n",
        "          \"log_Z\":log_partition_estimate.item(),\n",
        "          \"KL_loss_no_ebm\": KL_loss.item(),\n",
        "          \"energy_approximate\": energy_approximate.mean().item(),\n",
        "          \"energy_base_dist\": energy_base_dist.mean().item(),\n",
        "          \"approx_elbo\" : -loss_total.item(),\n",
        "      }\n",
        "\n",
        "\n",
        "      optE.step()\n",
        "      if not fix_decoder :\n",
        "        optG.step()\n",
        "      if not fix_encoder :\n",
        "        optEncoder.step()\n",
        "\n",
        "      if i%log_every == 0 :\n",
        "        log(i, dic_loss, logger)\n",
        "      if i%save_image_every== 0:\n",
        "        z_e_k, z_g_k = sample_langevin_prior(z_e_0, E), sample_langevin_posterior(z_g_0, x, G, E)\n",
        "        x_prior_langevin = G(z_e_k)\n",
        "        x_prior = G(z_e_0)\n",
        "        x_posterior = G(z_g_k)\n",
        "        x_approximate_posterior = G(z_q)\n",
        "        draw_samples(fig, axs, x_prior[:64], x_prior_langevin[:64], x_posterior[:64], x_approximate_posterior[:64], i, dic_loss, logger)\n"
      ],
      "metadata": {
        "id": "eN3e4sfC3Zzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def train_elbo_withtrick_v2(n_iter, G, E, Encoder, loss, optE, optG, optEncoder, cfg, logger= None):\n",
        "\n",
        "  fix_encoder = cfg[\"fix_encoder\"]\n",
        "  fix_decoder= cfg[\"fix_decoder\"]\n",
        "  log_var_p = None\n",
        "  device = next(G.parameters()).device\n",
        "  base_dist = torch.distributions.normal.Normal(torch.tensor(0,device=device),torch.tensor(1,device=device))\n",
        "  proposal = torch.distributions.normal.Normal(torch.tensor(cfg[\"proposal_mean\"],device=device, dtype=torch.float32),torch.tensor(cfg[\"proposal_std\"],device=device, dtype=torch.float32))\n",
        "\n",
        "\n",
        "  for i in range(n_iter):\n",
        "      optG.zero_grad()\n",
        "      optE.zero_grad()\n",
        "      optEncoder.zero_grad()\n",
        "      x = sample_p_data()\n",
        "\n",
        "      z_e_0, z_g_0 = sample_p_0(), sample_p_0()\n",
        "      mu_q, log_var_q = Encoder(x).chunk(2,1)\n",
        "      log_var_p = torch.log(torch.full_like(log_var_q, llhd_sigma)).pow(2)\n",
        "      std_q = torch.exp(0.5*log_var_q)\n",
        "\n",
        "      # Reparam trick\n",
        "      eps = torch.randn_like(mu_q)\n",
        "      z_q = (eps.mul(std_q).add_(mu_q)).reshape(-1,nz,1,1)\n",
        "      x_hat = G(z_q)\n",
        "\n",
        "\n",
        "      # Gaussian loss :\n",
        "      loss_g = (mse(x_hat, x) / batch_size)/(llhd_sigma**2)\n",
        "\n",
        "      # KL without ebm\n",
        "      KL_loss = 0.5 * (log_var_p - log_var_q -1 +  (log_var_q.exp() + mu_q.pow(2))/log_var_p.exp())\n",
        "      KL_loss = KL_loss.sum(dim=1).mean(dim=0)\n",
        "\n",
        "      # Entropy posterior\n",
        "      entropy_posterior = torch.sum(0.5* (math.log(2*math.pi) +  log_var_q + 1), dim=1).mean()\n",
        "\n",
        "      # Energy Proposal\n",
        "      z_proposal = proposal.sample((z_e_0.shape[0], nz,1,1))\n",
        "      energy_approximate = E(z_q).flatten(1).sum(1)\n",
        "      energy_proposal = E(z_proposal).flatten(1).sum(1)\n",
        "      energy_prior = E(z_e_0).flatten(1).sum(1)\n",
        "\n",
        "      base_dist_z_proposal = base_dist.log_prob(z_proposal.flatten(1)).sum(1)\n",
        "      base_dist_z_posterior = base_dist.log_prob(z_q.flatten(1)).sum(1)\n",
        "      base_dist_z_base_dist = base_dist.log_prob(z_e_0.flatten(1)).sum(1)\n",
        "      proposal_z_proposal = proposal.log_prob(z_proposal.flatten(1)).sum(1)\n",
        "      proposal_z_posterior = proposal.log_prob(z_q.flatten(1)).sum(1)\n",
        "      proposal_z_base_dist = proposal.log_prob(z_e_0.flatten(1)).sum(1)\n",
        "\n",
        "\n",
        "      log_partition_estimate = torch.logsumexp(-energy_proposal - proposal_z_proposal,0) - math.log(energy_proposal.shape[0])\n",
        "      loss_ebm = energy_approximate.mean() + log_partition_estimate.exp() -1\n",
        "      # loss_ebm =  energy_approximate.mean() + log_partition_estimate\n",
        "\n",
        "      loss_total = loss_g + KL_loss + loss_ebm\n",
        "      regularization(E, z_q, z_e_0, energy_approximate, energy_proposal, cfg, logger,i)\n",
        "      loss_total.backward()\n",
        "      grad_clipping_all_net([E,G,Encoder], [\"E\", \"G\", \"Encoder\"], [optE, optG, optEncoder,], logger, cfg, i)\n",
        "\n",
        "      dic_loss = {\n",
        "          \"loss_g\": loss_g.item(),\n",
        "          \"entropy_posterior\": entropy_posterior.item(),\n",
        "          \"loss_ebm\": loss_ebm.item(),\n",
        "          \"log_Z\": log_partition_estimate.item(),\n",
        "          \"KL_loss_no_ebm\": KL_loss.item(),\n",
        "          \"energy_approximate\": energy_approximate.mean().item(),\n",
        "          \"energy_proposal\" : energy_proposal.mean().item(),\n",
        "          \"energy_prior\": energy_prior.mean().item(),\n",
        "          \"base_dist_z_proposal\": base_dist_z_proposal.mean().item(),\n",
        "          \"base_dist_z_posterior\":base_dist_z_posterior.mean().item(),\n",
        "          \"base_dist_z_base_dist\": base_dist_z_base_dist.mean().item(),\n",
        "          \"proposal_z_proposal\": proposal_z_proposal.mean().item(),\n",
        "          \"proposal_z_posterior\":proposal_z_posterior.mean().item(),\n",
        "          \"proposal_z_base_dist\": proposal_z_base_dist.mean().item(),\n",
        "          \"approx_elbo\" : -loss_total.item(),\n",
        "      }\n",
        "\n",
        "\n",
        "      optE.step()\n",
        "      if not fix_decoder :\n",
        "        optG.step()\n",
        "      if not fix_encoder :\n",
        "        optEncoder.step()\n",
        "\n",
        "      if i%log_every == 0 :\n",
        "        log(i, dic_loss, logger)\n",
        "      if i%save_image_every== 0:\n",
        "        z_e_k, z_g_k = sample_langevin_prior(z_e_0, E), sample_langevin_posterior(z_g_0, x, G, E)\n",
        "        x_prior_langevin = G(z_e_k)\n",
        "        x_prior = G(z_e_0)\n",
        "        x_posterior = G(z_g_k)\n",
        "        x_approximate_posterior = G(z_q)\n",
        "        draw_samples(fig, axs, x_prior[:64], x_prior_langevin[:64], x_posterior[:64], x_approximate_posterior[:64], i, dic_loss, logger)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DasusDZjnBQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "ZMDdivPYd2jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cfg_clipping = {\n",
        "    \"E_clip_grad_type\": \"norm\",\n",
        "    \"E_clip_grad_value\": 0.5,\n",
        "    \"E_nb_sigma\": 3,\n",
        "\n",
        "    \"G_clip_grad_type\": \"norm\",\n",
        "    \"G_clip_grad_value\": 0.5,\n",
        "    \"G_nb_sigma\": 3,\n",
        "\n",
        "    \"Encoder_clip_grad_type\": \"norm\",\n",
        "    \"Encoder_clip_grad_value\": 0.5,\n",
        "    \"Encoder_nb_sigma\": 3,\n",
        "}\n",
        "\n",
        "cfg_regularization = {\n",
        "    \"l2_grad\":0.0,\n",
        "    \"l2_param\":1.0,\n",
        "    \"l2_output\":0.0,\n",
        "}\n",
        "\n",
        "cfg_proposal = {\n",
        "    \"proposal_mean\" : 0.0,\n",
        "    \"proposal_std\" : 1.0,\n",
        "}\n",
        "\n",
        "cfg.update(cfg_proposal)\n",
        "cfg.update(cfg_clipping)\n",
        "cfg.update(cfg_regularization)"
      ],
      "metadata": {
        "id": "ltcxq9dik3xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1,4, figsize=(20,5))\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "cfg.update({\"lr_E\" : 0.00005,\n",
        "            \"beta_1_E\": 0.5,\n",
        "            \"beta_2_E\":0.999,\n",
        "            \"lr_G\" : 0.0001,\n",
        "            \"beta_1_G\": 0.5,\n",
        "            \"beta_2_G\":0.999,\n",
        "            \"lr_Enc\" : 0.0001,\n",
        "            \"beta_1_Enc\": 0.5,\n",
        "            \"beta_2_Enc\":0.999,\n",
        "})\n",
        "logger = wandb.init(project=\"LatentEBM\", config=cfg)\n",
        "\n",
        "G = _G().to(device)\n",
        "E = _E().to(device)\n",
        "Encoder = _Encoder().to(device)\n",
        "mse = nn.MSELoss(reduction='sum')\n",
        "optE = t.optim.Adam(E.parameters(), lr=cfg[\"lr_E\"], betas=(cfg[\"beta_1_E\"], cfg[\"beta_2_E\"]))\n",
        "optG = t.optim.Adam(G.parameters(), lr=cfg[\"lr_G\"], betas=(cfg[\"beta_1_G\"], cfg[\"beta_2_G\"]))\n",
        "optEncoder = t.optim.Adam(Encoder.parameters(), lr=cfg[\"lr_Enc\"], betas=(cfg[\"beta_1_Enc\"], cfg[\"beta_2_Enc\"]))\n",
        "# train_elbo_notrick(500, G, E, Encoder, mse, optE, optG, optEncoder, logger)\n",
        "# train_auto_encoder(1000, G, E, Encoder, mse, optE, optG, optEncoder)\n",
        "# train_cd(1000, G, E, mse, optE, optG)\n",
        "# train_cd_trick(n_iter,G,E,mse,optE,optG, logger)"
      ],
      "metadata": {
        "id": "LYcX8SwOzKiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cfg.update({\"lr_E\" : 0.00002,\n",
        "            \"beta_1_E\": 0.5,\n",
        "            \"beta_2_E\":0.999,\n",
        "            \"lr_G\" : 0.00002,\n",
        "            \"beta_1_G\": 0.5,\n",
        "            \"beta_2_G\":0.999,\n",
        "            \"lr_Enc\" : 0.00002,\n",
        "            \"beta_1_Enc\": 0.5,\n",
        "            \"beta_2_Enc\":0.999,\n",
        "            \"trainer\": \"tricky_elbo\",\n",
        "            \"fix_encoder\": False,\n",
        "            \"fix_decoder\": False,\n",
        "            \"proposal_mean\": 0,\n",
        "            \"proposal_std\":1,\n",
        "\n",
        "})\n",
        "\n",
        "\n",
        "logger = wandb.init(project=\"LatentEBM\", config=cfg)\n",
        "\n",
        "G2 = _G()\n",
        "E2 = _E()\n",
        "Encoder2 = _Encoder()\n",
        "for p1, p2 in zip(G.parameters(),G2.parameters()):\n",
        "  p2.data = p1.data.clone()\n",
        "\n",
        "for p1, p2 in zip(E.parameters(),E2.parameters()):\n",
        "  p2.data = p1.data.clone()\n",
        "\n",
        "for p1, p2 in zip(Encoder.parameters(),Encoder2.parameters()):\n",
        "  p2.data = p1.data.clone()\n",
        "\n",
        "optE2 = t.optim.Adam(E2.parameters(), lr=cfg[\"lr_E\"], betas=(cfg[\"beta_1_E\"], cfg[\"beta_2_E\"]))\n",
        "optG2 = t.optim.Adam(G2.parameters(), lr=cfg[\"lr_G\"], betas=(cfg[\"beta_1_G\"], cfg[\"beta_2_G\"]))\n",
        "optEncoder2 = t.optim.Adam(Encoder2.parameters(), lr=cfg[\"lr_Enc\"], betas=(cfg[\"beta_1_Enc\"], cfg[\"beta_2_Enc\"]))\n",
        "\n",
        "train_elbo_withtrick(n_iter, G2, E2, Encoder2, mse, optE2, optG2, optEncoder2, cfg, logger)\n",
        "# train_elbo_withtrick_v2(n_iter, G2, E2, Encoder2, mse, optE2, optG2, optEncoder2, cfg, logger)"
      ],
      "metadata": {
        "id": "9edj7IrzB_1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eqp0AaiOD2JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D5NoqD_Pzv7p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}